---
title: 'Data Challenge #2'
authors: "Brandon Wolff, Zachary Heinemann, and Stephanie Langeland"
due date: "3/22/2017"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Review the data: 
```{r}
rm(list = ls(all = TRUE))   # cleans everything in the workspace

library(readr)          # easier reading of flat files
library(caret)          # classification and regresssion training package
library(randomForest)   # Random Forests package

# ::::::: SOME USEFUL DEFINITIONS :::::::::::::::::::::::::::::::::::::::::::::  

# set the general path for the project at its root, specific files will define 
# their own branches individually
# NOTE that specifying your path will be different in Windows

path <- "/Users/StephanieLangeland/Desktop/Columbia/Applied Data Science/Git/QMSS_G5069_Applied_D_S/Data Challenges/datachallenge2" ## Stephanie's path

# path <- "" ## Brandon's path

# path <- "" ## Zach's path

# define additional paths for files you will use. In each case, determine
# appropriate additions to the path

inFileName1   <- "data/processed/AllViolenceData_170216.csv"     # cleaned data on violence
outFileName1  <- "graphs/RF_VarImportance.pdf"       
outFileName2  <- "graphs/RF_MSE.pdf"  

# ::::::: APPLY INITIAL DEFINITIONS ::::::::::::::::::::::::::::::::::::::::::: 

# set your path to that defined above, and confirm it
setwd(path)   
getwd()

# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: 
# :::::::::::::::::::::: LOADS DATA :::::::::::::::::::::::::::::::::::::::::::  


# ::::::: LOADING RAW DATA
# note that read_csv() guesses column types, so that date is read as a date 
# very useful for plotting time series

AllData <- read_csv(inFileName1) 

# rough validations that data was correctly loaded
names(AllData)
nrow(AllData)
summary(AllData)

## The authories involved in each event are noted in their own columns in the 
## dataset.  For example when `AllData$army == 1` the army was involved.
## Guide to authority lookup:
auth_lookup <- "data/external/LookupAuthorityNames.csv"
auth_lookup_data <- read.csv(auth_lookup)
```

This is a team assignment. Please create a file on your team GitHub repo where 
you answer the challenge, including links to your code, and graphs.

#__Model #1 for question #1:__

###1.	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our dataset. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Are all weapons (defined as `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized`) seized and organized crime wounded good predictors for the number 
  of people detained?

###1a	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that

  * The variables `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized` will be summed into one variable name `weapons_seized`.
  
  * Make a new variable named `detained_resp` for to record whether people 
  where detained (1) or not (0) in order to do a response prediction.
  
```{r}
AllData$weapons_seized <- transform(AllData$clips.seized + 
                                      AllData$cartridge.sezied +
                                      AllData$small.arms.seized +
                                      AllData$long.guns.seized)

typeof(AllData$weapons_seized)
AllData$weapons_seized <- as.numeric(unlist((AllData$weapons_seized)))

AllData$detained_resp <- ifelse(AllData$detained > 1, 1, 0)

AllData <- as.data.frame(AllData)
```

###1b	show the output from your analysis in a consumable form
  * 

```{r}
set.seed(1234)
train <- sample(nrow(AllData), 2698)
training <- AllData[train, ]
testing <- AllData[-train, ]

linear <- lm(detained_resp ~ weapons_seized + organized.crime.wounded, 
             data = training)

quadratic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 2),
                data = training)
 
cubic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
            data = training)

quartic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
              data = training)

p_linear <- predict(linear, newdata = testing, type = "response")
table(testing$detained_resp, as.integer(p_linear > 0))
 
p_quadratic <- predict(quadratic, newdata = testing)
p_cubic <- predict(cubic, newdata = testing)
p_quartic <- predict(quartic, newdata = testing)


```

###1c	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * 
  
```{r}

```

###1d	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * 
  
```{r}

```

###1e	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * 
  
```{r}

```

###1f	provide your code, and a single visualization per question that summarizes 
###your finding
  * 
  
```{r}
library(ggplot2)
```

###1g	phrase your finding for each question in two ways:
###1g-1	one sentence that summarizes your insight
  * 

###1g-2	one paragraph that reflects all nuance in your insight
  * 
        
###1h	make sure to also include your code
  
  * The code is included under each quetsion above.
  
#__Model #2 for question #1:__

###1.	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our datas et. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Brandon
   
```{r}

```

###1a	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that
  * 
  
```{r}

```

###1b	show the output from your analysis in a consumable form
  * 

```{r}

```

###1c	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * 
  
```{r}

```

###1d	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * 
  
```{r}

```

###1e	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * 
  
```{r}

```

###1f	provide your code, and a single visualization per question that summarizes 
###your finding
  * 
  
```{r}

```

###1g	phrase your finding for each question in two ways:
###1g-1	one sentence that summarizes your insight
  * 

###1g-2	one paragraph that reflects all nuance in your insight
  * 
        
###1h	make sure to also include your code
  
  * The code is included under each quetsion above.
  
#__Model #1 for question #2:__
  
###2.	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH 

```{r}

```

  
###2a	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c	show the output from your analysis in a consumable form
  * 

```{r}

```

###2d	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e	be explicit in your assumptions
  * 
  
###2f	be explicit in the limitations of your inferences
  * 
  
###2g	phrase your finding for each question in two ways:
###2g-1	one sentence that summarizes your insight
  * 
  
###2g-2	one paragraph that reflects all nuance in your insight
  * 
  
###2h	make sure to also include your code
  
  * The code is included under each quetsion above.

#__Model #1 for question #2:__

###2.	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH:  

```{r}

```
  
###2a	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c	show the output from your analysis in a consumable form
  * 

```{r}

```

###2d	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e	be explicit in your assumptions
  * 
  
###2f	be explicit in the limitations of your inferences
  * 
  
###2g	phrase your finding for each question in two ways:
###2g-1	one sentence that summarizes your insight
  * 
  
###2g-2	one paragraph that reflects all nuance in your insight
  * 
  
###2h	make sure to also include your code
  
  * The code is included under each quetsion above.
  
  