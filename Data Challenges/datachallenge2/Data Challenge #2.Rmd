---
title: 'Data Challenge #2'
authors: "Brandon Wolff, Zachary Heinemann, and Stephanie Langeland"
due date: "3/22/2017"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Review the data: 
```{r}
rm(list = ls(all = TRUE))   # cleans everything in the workspace

library(readr)          # easier reading of flat files
library(caret)          # classification and regresssion training package
library(randomForest)   # Random Forests package

# ::::::: SOME USEFUL DEFINITIONS :::::::::::::::::::::::::::::::::::::::::::::  

# set the general path for the project at its root, specific files will define 
# their own branches individually
# NOTE that specifying your path will be different in Windows

path <- "/Users/StephanieLangeland/Desktop/Columbia/Applied Data Science/Git/QMSS_G5069_Applied_D_S/Data Challenges/datachallenge2" ## Stephanie's path

# path <- "" ## Brandon's path

# path <- "" ## Zach's path

# define additional paths for files you will use. In each case, determine
# appropriate additions to the path

inFileName1   <- "data/processed/AllViolenceData_170216.csv"     # cleaned data on violence
outFileName1  <- "graphs/RF_VarImportance.pdf"       
outFileName2  <- "graphs/RF_MSE.pdf"  

# ::::::: APPLY INITIAL DEFINITIONS ::::::::::::::::::::::::::::::::::::::::::: 

# set your path to that defined above, and confirm it
setwd(path)   
getwd()

# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: 
# :::::::::::::::::::::: LOADS DATA :::::::::::::::::::::::::::::::::::::::::::  


# ::::::: LOADING RAW DATA
# note that read_csv() guesses column types, so that date is read as a date 
# very useful for plotting time series

AllData <- read_csv(inFileName1) 

# rough validations that data was correctly loaded
## names(AllData)
## nrow(AllData)
## summary(AllData)

## The authories involved in each event are noted in their own columns in the 
## dataset.  For example when `AllData$army == 1` the army was involved.
## Guide to authority lookup:
auth_lookup <- "data/external/LookupAuthorityNames.csv"
auth_lookup_data <- read.csv(auth_lookup)
```

This is a team assignment. Please create a file on your team GitHub repo where 
you answer the challenge, including links to your code, and graphs.

#__Model #1 for question #1:__

###1.)	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our dataset. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Which regression model best predicts whether or not people will be detained using 
  all weapons (defined as `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized`) seized and wounded organized crime members as predictors?

###1a)	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that

  * The variables `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized` will be summed into one variable named `weapons_seized`.
  
  * A new variable will be created named `detained_resp` to record whether people 
  where detained (`1`) or not (`0`) in order to predict the response of whether
  people will be detained or not.
  
```{r}
AllData$weapons_seized <- transform(AllData$clips.seized + 
                                      AllData$cartridge.sezied +
                                      AllData$small.arms.seized +
                                      AllData$long.guns.seized)

typeof(AllData$weapons_seized)
AllData$weapons_seized <- as.numeric(unlist((AllData$weapons_seized))) # convert from list to numeric for regression models

AllData$detained_resp <- ifelse(AllData$detained > 0, 1, 0) 

AllData <- as.data.frame(AllData)
```

###1b)	show the output from your analysis in a consumable form
  * Regression Models:
```{r}
set.seed(1234)  # for reproducibility 
train <- sample(nrow(AllData), 2698) # randomly sample half of the data
training <- AllData[train, ] # create training set
testing <- AllData[-train, ] # create testing set

linear <- lm(detained_resp ~ weapons_seized + organized.crime.wounded, 
             data = training) # linear regression 

quadratic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 2),
                data = training) # quadratic regression
 
cubic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
            data = training) # cubic regression

quartic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 4),
              data = training) # quartic regression

p_linear <- predict(linear, newdata = testing, type = "response") # predict the repsonse 
p_liner_table <- confusionMatrix(testing$detained_resp, as.integer(p_linear > 0.5)) # confusion matrix
 
p_quadratic <- predict(quadratic, newdata = testing, type = "response")
p_quadratic_table <- confusionMatrix(testing$detained_resp, as.integer(p_quadratic > 0.5)) 

p_cubic <- predict(cubic, newdata = testing, type = "response")
p_cubic_table <- confusionMatrix(testing$detained_resp, as.integer(p_cubic > 0.5))

p_quartic <- predict(quartic, newdata = testing, type = "response")
p_quartic_table <- confusionMatrix(testing$detained_resp, as.integer(p_quartic > 0.5))
```
  * Regression Results:
  A confusion matrix was constructed for each of the models and ranked in 
  order from worst to best prediction accuracy:
```{r}
p_quadratic_table # quadratic regression confusion matrix 
p_liner_table # linear regression confusion matrix 
p_quartic_table # quartic regression confusion matrix
p_cubic_table # cubic regression confusion matrix 
```
  * __Analysis of the output:__  The cubic regression model had the highest 
  prediction accuracy of 0.7135 or 71.35% in using wounded organized crime members
  and all weapons seized to predict whether people would be detained or not.  The
  cubic confusion matrix shows that the model correctly predicted that no one
  would be detained 1,875 times and people would be detained 50 times. Although 
  the model has the highest prediction accuracy, it is mainly driven by correct 
  predictions of no one being detained.  Overall, it does not successfully 
  predict when people will be detained.  Therefore, this model will not help
  Mexican authorities understand drivers of detention rates, since it does not
  consistently predict how the number of organized crime members wounded and weapons seized
  relate to whether people are detained or not. Furhermore, the model incorrectly
  predicted that people would be detained in 737 events when no one was detained.
  It also incorrectly predicted that people would not be detained when people were
  detained in 36 events.

###1c)	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * The limitations of the cubic regression model are shown through various diagnostic 
  plots using the entire dataset.  Refer to the analysis below the plots. 

```{r}
plot(lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
        data = AllData)) # cubic regression
```  

  1.) __Residuals vs Fitted plot:__ This plot shows whether the residuals have non-linear 
  patterns.  Although the cubic model had the highest prediction accuracy of all
  the regression models,the residuals do not show cubic relationship on this plot,
  but rather two linear lines that have a clear turning point.  Therefore, the cubic
  nature of the model may not actually be the most appropriate fit for the data. This
  may help explain why there was unbalanced prediction accuracy in that more "not detained"
  cases were predicted than "detained" cases. 
  
  2.) __Normal Q-Q plot:__ This plot shows whether the residuals are normally distributed.  
  Since the residuals on the graph do not follow the straight dashed line, the data are not 
  normally distributed.  This may represent bias or skewness in the data, which may be 
  attributed to unbalanced cases of detained versus not detained.  If this is the case, 
  this may support the claim that there are more cases of people not being detained.
  
  3.) __Scale-Location plot:__ This plot shows whether the residuals are spread 
  equally along the ranges of predictors.  Since the predictors are not equally 
  spread throughout the graph, this suggests that the data suffer from heterscedasticity, 
  meaning that variance among the residuals is not equal.  This seriously 
  undermines the validity of the model because the modeling errors my not be 
  uncorrelated and uniform. 
  
  4.) __Residuals vs Leverage plot:__ This plot illumiates outliers that may 
  be influential to regresson results.  The extreme outliers # 135 and 1429 
  are outside of the Cookâ€™s distance (represented by the dotted line).  These
  cases are influential to the regression results, which will be altered if
  these cases are excluded from the model.

  __Conclusion:__ Given the analysis of the diagnostic plots above, the cubic 
  model has serious limitations that violate the basic regression assumptions.
  These limitations may invalidate the regression results.  The severity  of
  these limitations may become less influential as more data are collected.
  As more data are collected, theoretically, the distribution should normalize
  and become homoscedastic.
  
###1d)	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * It is interesting that the cubic model predicts the best out of all the models
    but the predicitons are skewed towards predicting when no one will be detained.
    This skewness in the prediction may be attributed to the findings noted in #1c 
    above related to the violations of regression assumptions, especially that the 
    data are notmally distributed. Predicting whether or not people will be detained 
    using all weapons seized and wounded organized crime members as predictors is not
    worth pursuing because the model poorly predicts cases when people will be detained.
    Moreover, since the model is not in compliance with the regression assumptions, the
    results may not be true findings. 

###1e)	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * 
  this won't help the authorities detain people but they couldn't use these models
  to understand that they should not be focused on seixing weapons and woudning organized crime
  members if the goal is to detain people.  additional info that would help - are here less 
  people detained overall in the dataset - is that why the models 
  aren't very good at predicting when people will be detained? 
  
```{r}
# quick tibble with count of 0's for detained_response and 1's in each column
which(AllData$detained_resp == 0)

nrow(AllData[AllData$detained_resp == 0,])
length(AllData$detained_resp[AllData$detained_resp == 0])
sum(which(AllData$detained_resp == 0))

nrow(filter(AllData, AllData$detained_resp == "0"))

library(tibble)
no_detained <- tibble(x = AllData$detained_resp == 0, y = AllData$weapons_seized)

library(ggplot2)

ggplot(data = AllData) +
  geom_histogram(mapping = aes(x = weapons_seized, y = detained_resp == 1))

ggplot(data = AllData) +
  geom_histogram(mapping = aes(x = weapons_seized, y = detained_resp, z = organized.crime.wounded))
```


###1f)	provide your code, and a single visualization per question that summarizes 
###your finding
  * refer to the plot functions?  or 
  make histogram of x = weapons, x = organized crime wounded, y = WHETHER people were detained?
  
```{r}

```

###1g)	phrase your finding for each question in two ways:
###1g-1)	one sentence that summarizes your insight
  * 

###1g-2)	one paragraph that reflects all nuance in your insight
  * 
        
###1h)	make sure to also include your code
  
  * The code is included under each quetsion above.
  
#__Model #2 for question #1:__

###1.)	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our datas et. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Brandon
   
```{r}

```

###1a)	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that
  * 
  
```{r}

```

###1b)	show the output from your analysis in a consumable form
  * 

```{r}

```

###1c)	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * 
  
```{r}

```

###1d)	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * 
  
```{r}

```

###1e)	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * 
  
```{r}

```

###1f)	provide your code, and a single visualization per question that summarizes 
###your finding
  * 
  
```{r}

```

###1g)	phrase your finding for each question in two ways:
###1g-1)	one sentence that summarizes your insight
  * 

###1g-2)	one paragraph that reflects all nuance in your insight
  * 
        
###1h)	make sure to also include your code
  
  * The code is included under each quetsion above.
  
#__Model #1 for question #2:__
  
###2.)	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH 

```{r}

```

  
###2a)	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b)	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c)	show the output from your analysis in a consumable form
  * 

```{r}

```

###2dv	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e)	be explicit in your assumptions
  * 
  
###2f	be explicit in the limitations of your inferences
  * 
  
###2g)	phrase your finding for each question in two ways:
###2g-1)	one sentence that summarizes your insight
  * 
  
###2g-2)	one paragraph that reflects all nuance in your insight
  * 
  
###2h)	make sure to also include your code
  
  * The code is included under each quetsion above.

#__Model #1 for question #2:__

###2.)	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH:  

```{r}

```
  
###2a)	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b)	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c)	show the output from your analysis in a consumable form
  * 

```{r}

```

###2d)	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e)	be explicit in your assumptions
  * 
  
###2f)	be explicit in the limitations of your inferences
  * 
  
###2g)	phrase your finding for each question in two ways:
###2g-1)	one sentence that summarizes your insight
  * 
  
###2g-2)	one paragraph that reflects all nuance in your insight
  * 
  
###2h)	make sure to also include your code
  
  * The code is included under each quetsion above.
  
  