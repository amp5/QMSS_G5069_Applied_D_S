---
title: 'Data Challenge #2'
authors: "Brandon Wolff, Zachary Heinemann, and Stephanie Langeland"
due date: "3/22/2017"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Review the data: 
```{r}
rm(list = ls(all = TRUE))   # cleans everything in the workspace

library(readr)          # easier reading of flat files
library(caret)          # classification and regresssion training package
library(randomForest)   # Random Forests package

# ::::::: SOME USEFUL DEFINITIONS :::::::::::::::::::::::::::::::::::::::::::::  

# set the general path for the project at its root, specific files will define 
# their own branches individually
# NOTE that specifying your path will be different in Windows

path <- "/Users/StephanieLangeland/Desktop/Columbia/Applied Data Science/Git/QMSS_G5069_Applied_D_S/Data Challenges/datachallenge2" ## Stephanie's path

# path <- "C:\\Users\\Brandon\\Documents\\GitHub\\QMSS_G5069_Applied_D_S\\Data Challenges\\datachallenge2" ## Brandon's path

# path <- "" ## Zach's path

# define additional paths for files you will use. In each case, determine
# appropriate additions to the path

inFileName1   <- "data/processed/AllViolenceData_170216.csv"     # cleaned data on violence
outFileName1  <- "graphs/RF_VarImportance.pdf"       
outFileName2  <- "graphs/RF_MSE.pdf"  

# ::::::: APPLY INITIAL DEFINITIONS ::::::::::::::::::::::::::::::::::::::::::: 

# set your path to that defined above, and confirm it
setwd(path)   
getwd()

# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: 
# :::::::::::::::::::::: LOADS DATA :::::::::::::::::::::::::::::::::::::::::::  


# ::::::: LOADING RAW DATA
# note that read_csv() guesses column types, so that date is read as a date 
# very useful for plotting time series

AllData <- read_csv(inFileName1) 

# rough validations that data was correctly loaded
## names(AllData)
## nrow(AllData)
## summary(AllData)

## The authories involved in each event are noted in their own columns in the 
## dataset.  For example when `AllData$army == 1` the army was involved.
## Guide to authority lookup:
auth_lookup <- "data/external/LookupAuthorityNames.csv"
auth_lookup_data <- read.csv(auth_lookup)
```

This is a team assignment. Please create a file on your team GitHub repo where 
you answer the challenge, including links to your code, and graphs.

#__Model #1 for question #1:__

###1.)	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our dataset. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Which regression model best predicts whether or not people will be detained using 
  all weapons (defined as `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized`) seized and wounded organized crime members as predictors?

###1a)	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that

  * The variables `clips.seized`, `cartridge.sezied`, `small.arms.seized`,
  `long.guns.seized` will be summed into one variable named `weapons_seized`.
  
  * A new variable will be created named `detained_resp` to record whether people 
  where detained (`1`) or not (`0`) in order to predict the response of whether
  people will be detained or not.
  
```{r}
AllData$weapons_seized <- transform(AllData$clips.seized + 
                                      AllData$cartridge.sezied +
                                      AllData$small.arms.seized +
                                      AllData$long.guns.seized)

typeof(AllData$weapons_seized)
AllData$weapons_seized <- as.numeric(unlist((AllData$weapons_seized))) 
# ^convert from list to numeric for regression models

AllData$detained_resp <- ifelse(AllData$detained > 0, 1, 0) 

AllData <- as.data.frame(AllData)
```

###1b)	show the output from your analysis in a consumable form
  * Regression Models:
```{r}
set.seed(1234)  # for reproducibility 
train <- sample(nrow(AllData), 2698) # randomly sample half of the data
training <- AllData[train, ] # create training set
testing <- AllData[-train, ] # create testing set

linear <- lm(detained_resp ~ weapons_seized + organized.crime.wounded, 
             data = training) # linear regression 

quadratic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 2),
                data = training) # quadratic regression
 
cubic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
            data = training) # cubic regression

quartic <- lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 4),
              data = training) # quartic regression

p_linear <- predict(linear, newdata = testing, type = "response") # predict the repsonse 
p_liner_table <- confusionMatrix(testing$detained_resp, as.integer(p_linear > 0.5)) 
# ^confusion matrix
 
p_quadratic <- predict(quadratic, newdata = testing, type = "response")
p_quadratic_table <- confusionMatrix(testing$detained_resp, as.integer(p_quadratic > 0.5)) 

p_cubic <- predict(cubic, newdata = testing, type = "response")
p_cubic_table <- confusionMatrix(testing$detained_resp, as.integer(p_cubic > 0.5))

p_quartic <- predict(quartic, newdata = testing, type = "response")
p_quartic_table <- confusionMatrix(testing$detained_resp, as.integer(p_quartic > 0.5))
```
  * Regression Results:
  A confusion matrix was constructed for each of the models and ranked in 
  order from worst to best prediction accuracy:
```{r}
p_quadratic_table # quadratic regression confusion matrix 
p_liner_table # linear regression confusion matrix 
p_quartic_table # quartic regression confusion matrix
p_cubic_table # cubic regression confusion matrix 
```
  *__Analysis of the output:__
  The cubic regression model had the highest 
  prediction accuracy of 0.7135 or 71.35% in using wounded organized crime members
  and all weapons seized to predict whether people would be detained or not.  The
  cubic confusion matrix shows that the model correctly predicted that no one
  would be detained 1,875 times and people would be detained 50 times. Although 
  the model has the highest prediction accuracy, it is mainly driven by correct 
  predictions of no one being detained.  Overall, it does not successfully 
  predict when people will be detained.  Therefore, this model will not help
  Mexican authorities understand drivers of detention rates, since it does not
  consistently predict how the number of organized crime members wounded and weapons seized
  relate to whether people are detained or not. Furhermore, the model incorrectly
  predicted that people would be detained in 737 events when no one was detained.
  It also incorrectly predicted that people would not be detained when people were
  detained in 36 events.

###1c)	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * The limitations of the cubic regression model are shown through various diagnostic 
  plots using the entire dataset.  Refer to the analysis below the plots. 

```{r}
plot(lm(detained_resp ~ poly(weapons_seized + organized.crime.wounded, degree = 3),
        data = AllData)) # cubic regression
```  

  1.) __Residuals vs Fitted plot:__ This plot shows whether the residuals have non-linear 
  patterns.  Although the cubic model had the highest prediction accuracy of all
  the regression models,the residuals do not show cubic relationship on this plot,
  but rather two linear lines that have a clear turning point.  Therefore, the cubic
  nature of the model may not actually be the most appropriate fit for the data. This
  may help explain why there was unbalanced prediction accuracy in that more "not detained"
  cases were predicted than "detained" cases. 
  
  2.) __Normal Q-Q plot:__ This plot shows whether the residuals are normally distributed.  
  Since the residuals on the graph do not follow the straight dashed line, the data are not 
  normally distributed.  This may represent bias or skewness in the data, which may be 
  attributed to unbalanced cases of detained versus not detained.  If this is the case, 
  this may support the claim that there are more cases of people not being detained.
  
  3.) __Scale-Location plot:__ This plot shows whether the residuals are spread 
  equally along the ranges of predictors.  Since the predictors are not equally 
  spread throughout the graph, this suggests that the data suffer from heterscedasticity, 
  meaning that variance among the residuals is not equal.  This seriously 
  undermines the validity of the model because the modeling errors my not be 
  uncorrelated and uniform. 
  
  4.) __Residuals vs Leverage plot:__ This plot illumiates outliers that may 
  be influential to regresson results.  The extreme outliers # 135 and 1429 
  are outside of the Cookâ€™s distance (represented by the dotted line).  These
  cases are influential to the regression results, which will be altered if
  these cases are excluded from the model.

  __Conclusion:__ Given the analysis of the diagnostic plots above, the cubic 
  model has serious limitations that violate the basic regression assumptions.
  These limitations may invalidate the regression results.  The severity  of
  these limitations may become less influential as more data are collected.
  As more data are collected, theoretically, the distribution should normalize
  and become homoscedastic.
  
###1d)	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * It is interesting that the cubic model predicts the best out of all the models
    but the predicitons are skewed towards predicting when no one will be detained.
    This skewness in the prediction may be attributed to the findings noted in #1c 
    above related to the violations of regression assumptions, especially that the 
    data are notmally distributed. Predicting whether or not people will be detained 
    using all weapons seized and wounded organized crime members as predictors is not
    worth pursuing because the model poorly predicts cases when people will be detained.
    Moreover, since the model is not in compliance with the regression assumptions, the
    results may not be true findings. 

###1e)	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * The poor prediction accuracy of the cubic model in predicting when people will 
  be detained may be attributed to the skewness of the data.  Below, we see that 
  there were 3,787 events when no one was detained and 1,609 when people were 
  detained.  Therefore, the model may not have enough data to better predict when
  people will be detained.  The model may be more effective once more data are 
  collected and the data become normally distributed. 
  
```{r}
nrow(AllData[AllData$detained_resp == "0",]) # Number of events when no one was detained
nrow(AllData[AllData$detained_resp == "1",]) # Number of events when people were detained

library(ggplot2)

ggplot(data = AllData) +
  geom_histogram(mapping = aes(detained_resp)) +
  xlab("No One Detained (x = 0) vs. Detained (x = 1")
```

###1f)	provide your code, and a single visualization per question that summarizes 
###your finding
  * need help graphing fitted (p_cubic) vs. actual (cubic) values 
  
```{r}
ggplot()

ggplot(training, aes(cubic)) + 
   geom_line() +
   geom_line(data = testing, color = "red")

ggplot(data = AllData) +
  geom_point(mapping = aes(x = weapons_seized, y = detained_resp), color = "red") +
  geom_point(mapping = aes(x = weapons_seized, y = detained_resp), color = "red") +
  geom_point(mapping = aes(x = organized.crime.wounded, y = detained_resp), color = "blue") #+
#  geom_smooth()

ggplot(data = training, testing) +
  geom_point(aes(cubic, p_cubic)) #+
  #geom_point(aes(p_cubic))

plot(AllData$organized.crime.wounded, AllData$detained_resp, 
     xlim = range(AllData$organized.crime.wounded, AllData$weapons_seized), 
     ylim = range(AllData$detained_resp, AllData$detained_resp)) 

points(AllData$weapons_seized, AllData$detained_resp, col='red') 

ggplot(AllData) + 
  geom_jitter(aes(weapons_seized, detained_resp), color = "blue") + 
  geom_smooth(aes(weapons_seized, detained_resp), method = lm, se = TRUE) +
  geom_jitter(aes(organized.crime.wounded, detained_resp), color = "green") + 
  geom_smooth(aes(organized.crime.wounded, detained_resp), method = lm, se = TRUE) +
  labs(x = "Predicted", 
       y = "Number of Detained")
```

###1g)	phrase your finding for each question in two ways:
###1g-1)	one sentence that summarizes your insight
  * A cubic model used the number of organized crime members wounded and weapons 
  seized per event to successfully predict when people will not be detained but 
  not when people will be detained with the same level of accuracy. 

###1g-2)	one paragraph that reflects all nuance in your insight
  * A cubic model used the number of organized crime members wounded and weapons 
  seized per event to successfully predict when people will not be detained but 
  not when people will be detained with the same level of accuracy. The distribution
  of the data is not normal and skewed with more cases when people were not detained.
  Additionally, the data suffers from heteroscedasticity and extreme outliers that
  influence the regression results.  Overall, the cubic model violates multiple
  regression assumptions and the ouput is not useful in predicting when people will
  be detained.
        
###1h)	make sure to also include your code
  * The code is included under each quetsion above.
  
#__Model #2 for question #1:__

###1.	Ask two (2) questions that might help you understand better the dynamics of 
###violence contained on our datas et. Apply one algorithm per question and share 
###your insights from each analysis. [50 pts] Remember: a non-finding is also a 
###finding! It tells you whether a question is worth pursuing further or not.
  
  * Does the specific government group involved with an event (AFI, Army, 
  Federal Police, Ministerial Police, Municipal Police, Navy, Other, and State 
  Police) have a positive or negative relationship with Perfect Lethality? We can 
  see from the graph below that there are about 1500 cases with perfect lethality 
  therefore I believe it is acceptable to examine this question.
   
```{r}
library(ggplot2)
pl <- ggplot(AllData, aes(perfect.lethality))
pl + geom_bar()
```

###1a	perform the necessary transformations in your data - if any are needed, 
###and explain why you did that
  * We used the same code used above to create a variable for total weaponry 
  seized (`weapons_seized`) by using the sum of the variables `clips.seized`,
  `cartridge.sezied`, `small.arms.seized`, `long.guns.seized`. This variable 
  will be used in order to control for all weaponary seized in our analysis.
  
```{r}
# used Stephanie's code to create one variable to sum weaponry seized
AllData$weapons_seized <- transform(AllData$clips.seized + 
                                      AllData$cartridge.sezied +
                                      AllData$small.arms.seized +
                                      AllData$long.guns.seized)
AllData$weapons_seized <- as.numeric(unlist((AllData$weapons_seized)))
```

###1b	show the output from your analysis in a consumable form
  * In order to answer our hypothesis we ran a multiple logistic regression on 
  perfect lethality by the involvment of the AFI, Army, Federal Police, 
  Ministerial Police, Municipal Police, Navy, Other, and State Police. A number 
  of control variables were also included which are municipality code, number of
  detained in the events, the date of each event, the total people dead in the 
  events, the total people wounded in the events, weaponry seized in the events, 
  and the source of the data for the events (Confrontations or Aggresions database). 
  We are using logistic regression becuase the variables being used are binary (0,1).  

```{r}
logit.perf_leth3 <- glm(perfect.lethality ~ afi + army + federal.police + ministerial.police + municipal.police + navy + other + state.police + mun_code + detained + date + total.people.dead + total.people.wounded + weapons_seized + source, family = binomial (link = logit), data = AllData)
summary(logit.perf_leth3)
```

###1c	be explicit about the limitations of your anaylisis, due to estimation 
###or to the data itself
  * There are a number of limitations with the anaylisis. One limitation is 
  that not all government groups were involved in a large sum of events. For 
  example, the Navy was only involved in 89 cases and the AFI was only involved 
  in 13 cases. The graphs below display the cases in which the navy and AFI were 
  involved. Having such a small sample can be problematic.   

```{r}
afi <- ggplot(AllData, aes(afi))
afi + geom_bar() +
      ggtitle("AFI")

n <- ggplot(AllData, aes(navy))
n + geom_bar() +
    ggtitle("NAVY")
```

It should also be noted that the 'source' of the data was highly significant 
in the model and if that variable is not included Ministerial Police, Municipal 
Police, and State Police involvment all  become significant. I beleive this is 
problematic becuase the two datasets might not be collected in the same fashion. 
This model with and without the variable 'source' can be viewed below. It is also 
a limitation that logistic models are more difficult to explain/interpret in 
comparison to simple linear regression models. 
  
```{r}
logit.perf_leth2 <- glm(perfect.lethality ~ afi + army + federal.police + 
                          ministerial.police + municipal.police + navy + 
                          other + state.police + mun_code + detained + 
                          date + total.people.dead + total.people.wounded + 
                          weapons_seized, family = binomial (link = logit), 
                        data = AllData)
summary(logit.perf_leth2)
summary(logit.perf_leth3)
#explain limitation with datasets and also explain how logit are hard to explain/interpret
```

###1d	did you find something interesting? what is that? does your finding 
###suggest this question is worth pursuing further? why or why not?
    * We found that the navy and the army seem to a statistically significant 
    and positive relationship to perfect lethality, controlling for all other 
    variables included in the model. This means that if the Army or Navy is 
    involved in an event the event has higher odds of being an event of perfect 
    lethality. I feel this finding does suggest this question is worth pursuing 
    further because it is important to know the effectivness of each individual 
    group to know what groups to send into specific situations. 
  
###1e	if you did not find something interesting, explain why, and whether 
###there is some additional information that would help in answering your question
  * 
  
###1f	provide your code, and a single visualization per question that summarizes 
###your finding
  
```{r fig.width=12, fig.height=12}
library(popbio)
par(mfrow = c(4, 2))

logi.hist.plot(AllData$army, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "ARMY Perfect Lethality", 
               xlabel = "ARMY Participation")

logi.hist.plot(AllData$afi, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "AFI Perfect Lethality", 
               xlabel = "AFI Participation")

logi.hist.plot(AllData$federal.police, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col="gray", 
               counts = TRUE, 
               mainlabel = "Federal Police Perfect Lethality", 
               xlabel = "Federal Police Participation")

logi.hist.plot(AllData$ministerial.police, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "Ministerial Police Perfect Lethality", 
               xlabel = "Ministerial Police Participation")

logi.hist.plot(AllData$municipal.police, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "Municipal Police Perfect Lethality", 
               xlabel = "Municipal Police Participation")

logi.hist.plot(AllData$navy, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE, 
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "NAVY Perfect Lethality", 
               xlabel = "NAVY Participation")

logi.hist.plot(AllData$other, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel ="OtherPerfect Lethality" , 
               xlabel = "Other Participation")

logi.hist.plot(AllData$state.police, 
               AllData$perfect.lethality, 
               boxp = FALSE, 
               rug = FALSE,
               logi.mod = 1, 
               type = "hist", 
               col = "gray", 
               counts = TRUE, 
               mainlabel = "State Police Perfect Lethality", 
               xlabel = "State Police Participation")
```


###1g	phrase your finding for each question in two ways:
###1g-1	one sentence that summarizes your insight
  * The invovlment of the Navy or Army in an event on average increase the 
  chances of said event being one of perfect lethality.

###1g-2	one paragraph that reflects all nuance in your insight
  * It is very interesting that the conttrol variables municipality code, number 
  of  detained in the events, the date of each event, the total people dead in 
  the events, the total people wounded in the events, and the source of the data 
  for the events (Confrontations or Aggresions database) all were statistically 
  significant. This means that the municipality in which the event took place is 
  related to whether or not the event was one of perfect lethality. This is a 
  question that could be further examined. It is also worth noting that the navy 
  was only included in 89 events yet 75 of the events were ones of perfect 
  lethality. When seeing those numbers it does seem clear that the navy is 
  important when it come to perfect lethality, yet they are not involved in 
  many cases whatsover. The Army on the other hand was involved in 1057 events
  and 797 of said events had perfect lethality. The army and the Navy seem to be 
  well trained at killing in comparison to the AFI, Federal Police, Ministerial 
  Police, Municipal Police, State Police, and other. 
        
###1h	make sure to also include your code
  * The code is included under each quetsion above.
  
#__Model #1 for question #2:__
  
###2.)	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH 

```{r}

```

  
###2a)	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b)	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c)	show the output from your analysis in a consumable form
  * 

```{r}

```

###2dv	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e)	be explicit in your assumptions
  * 
  
###2f	be explicit in the limitations of your inferences
  * 
  
###2g)	phrase your finding for each question in two ways:
###2g-1)	one sentence that summarizes your insight
  * 
  
###2g-2)	one paragraph that reflects all nuance in your insight
  * 
  
###2h)	make sure to also include your code
  
  * The code is included under each quetsion above.

#__Model #1 for question #2:__

###2.)	Formulate two (2) conditional hypotheses that you seek to investigate with 
###the data. One of your hypotheses should condition on two variables (as the 
###example on the slides), and the other should condition on three variables. [50 pts]
    
    * ZACH:  

```{r}

```
  
###2a)	formulate each one of your hypotheses explicitly in substantive terms (as 
###opposed to statistical terms) using 2-3 lines at most
  * 
  
###2b)	show exactly how each one of your hypotheses translates into the marginal 
###effect that you will seek to estimate from the data
  * 
  
###2c)	show the output from your analysis in a consumable form
  * 

```{r}

```

###2d)	show all your computations to estimate the corresponding marginal effect 
###and its standard error
  * 

```{r}

```

###2e)	be explicit in your assumptions
  * 
  
###2f)	be explicit in the limitations of your inferences
  * 
  
###2g)	phrase your finding for each question in two ways:
###2g-1)	one sentence that summarizes your insight
  * 
  
###2g-2)	one paragraph that reflects all nuance in your insight
  * 
  
###2h)	make sure to also include your code
  
  * The code is included under each quetsion above.
  
  